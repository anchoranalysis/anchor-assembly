<!-- 
===================
TASK:   coco
AUTHOR: Owen Feehan
===================

===========
DESCRIPTION
===========

Finds objects in images (instance segmentation).

It uses a Mask-RCNN deep learning model trained on the MSCOCO Dataset to propose object-masks, each with a confidence score.

A non-maxima suppression algorithm reduces the proposed objects to a smaller set by eliminating significantly overlapping proposals.


======
INPUTS
======

RGB or grayscale images


=======
OUTPUTS
=======

objects:
    HDF5 object-masks for all the bounding-boxes that are eventually accepted

mask:
    a binary-mask combining all the object-masks in an image

outline:
    a green outline imposed on the original RGB around each object-mask


-->
<config>
<bean config-class="org.anchoranalysis.plugin.image.task.bean.segment.SegmentInstanceWithModel">
	<segment config-class="org.anchoranalysis.image.inference.bean.segment.instance.SuppressNonMaxima">
		<segment readFromResources="true" modelPath="MaskRCNN-10.onnx" inputName="image" classLabelsPath="mscoco_labels.names" config-class="org.anchoranalysis.plugin.onnx.bean.object.segment.stack.SegmentObjectsFromONNXModel">
			<decode minConfidence="0.5" minMaskValue="0.3" config-class="org.anchoranalysis.plugin.onnx.bean.object.segment.decode.instance.DecodeMaskRCNN"/>
			<scaleInput preserveAspectRatio="false" config-class="org.anchoranalysis.plugin.image.bean.scale.ToDimensions">
				<dimensions config-class="org.anchoranalysis.plugin.image.bean.dimensions.provider.SpecifyDimensions">
					<sizeXY width="1088" height="800" config-class="org.anchoranalysis.image.bean.spatial.SizeXY"/>
				</dimensions>
			</scaleInput>
			<subtractMean items="102.9801,115.9465,122.7717" config-class="org.anchoranalysis.bean.primitive.DoubleList" config-factory="doubleList"/>
		</segment>
		<reduce config-class="org.anchoranalysis.image.inference.bean.reduce.RemoveOverlappingObjects"/>
	</segment>
</bean>
</config>
